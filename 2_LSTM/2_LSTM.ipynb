{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "007_LSTM_Lyrics_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on771oapUaG1"
      },
      "source": [
        "# LSTM: TF-IDF의 키워드를 통해 가사 한줄을 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A0KYkGTUhT8"
      },
      "source": [
        "## 1. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WixXofMaeeAG",
        "outputId": "aca5088b-618b-44f5-cefc-43b56b410b18"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 22 11:01:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    36W / 250W |    849MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0tGF39jQ_qs"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0FVYmeURA0u",
        "outputId": "f3a60cf0-e84e-4604-adaa-f4f89f46155a"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 49.5MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjdJXlcgREF6"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjHdvFSLRGUD"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQc514Q-TELm"
      },
      "source": [
        "# from konlpy.tag import Okt\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models import FastText\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfRS9154TDSK"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import skipgrams, pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, LSTM\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxWzAU-QTJTj"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljrqtDvHUuTU"
      },
      "source": [
        "## 2. Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwCI0AEpRHzb",
        "outputId": "1316e1fd-5482-40e8-b927-79301b2eadd2"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLpXkSAVUyR6",
        "outputId": "49563d76-2bb5-45c8-c254-b597bf155b4d"
      },
      "source": [
        "% cd /content/drive/MyDrive/Colab\\ Notebooks/Project/Lyrics/2_LSTM/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Project/Lyrics/2_LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0HI383EX8wU",
        "outputId": "321b712e-b1f1-4a7a-afc9-eacae3b2beae"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G5acTVPSxuo"
      },
      "source": [
        "## 3. 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBwtNh1KSqbC"
      },
      "source": [
        "PATH = '../Data/2_LSTM_Ballard_Data.csv'\n",
        "\n",
        "df = pd.read_csv(PATH)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "jYiCRmapSwpz",
        "outputId": "e47d7fae-eac8-4a21-c5f1-3d645d0ea5b7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>singer</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>너희는 (Feat. 김광률)</td>\n",
              "      <td>이은영</td>\n",
              "      <td>너희는 하나님의 택하신\\n거룩하고 사랑스러운 자니 \\n긍율과 자비와 \\n겸손과 온유...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>봄날은 간다 (Bonus Track)</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>눈을 감으면 문득 그리운 날의 기억 \\n아직까지도 마음이 저려 오는 건 \\n\\n그건...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Going Home</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>집으로 돌아가는 길에\\n지는 햇살에 마음을 맡기고\\n나는 너의 일을 떠올리며\\n수많...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>야상곡 (夜想曲)</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>바람이 부는 것은 더운 내 맘 삭여주려 \\n계절이 다 가도록 나는 애만 태우네 \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>길</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>아무도 가르쳐 주지 않아\\n이 길이 옳은지 다른 길로 가야 할지\\n난 저길 저 끝에...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             lyrics\n",
              "0           0  ...  너희는 하나님의 택하신\\n거룩하고 사랑스러운 자니 \\n긍율과 자비와 \\n겸손과 온유...\n",
              "1           1  ...  눈을 감으면 문득 그리운 날의 기억 \\n아직까지도 마음이 저려 오는 건 \\n\\n그건...\n",
              "2           2  ...  집으로 돌아가는 길에\\n지는 햇살에 마음을 맡기고\\n나는 너의 일을 떠올리며\\n수많...\n",
              "3           3  ...  바람이 부는 것은 더운 내 맘 삭여주려 \\n계절이 다 가도록 나는 애만 태우네 \\n...\n",
              "4           4  ...  아무도 가르쳐 주지 않아\\n이 길이 옳은지 다른 길로 가야 할지\\n난 저길 저 끝에...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPSUlEAoS2TI"
      },
      "source": [
        "## 4. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EBFVxtkYnny"
      },
      "source": [
        "- 결측치 제거/ 한글 외 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqegFNUFS4fi"
      },
      "source": [
        "df.dropna(axis=0, inplace = True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPKCiU5UKD5d"
      },
      "source": [
        "df['lyrics'] = df['lyrics'].str.replace('[^가-힣\\n]' , ' ')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "hDqFYuK8KFx8",
        "outputId": "b2c6d633-eb68-45f9-c2cf-f35da878ae92"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>singer</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>너희는 (Feat. 김광률)</td>\n",
              "      <td>이은영</td>\n",
              "      <td>너희는 하나님의 택하신\\n거룩하고 사랑스러운 자니 \\n긍율과 자비와 \\n겸손과 온유...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>봄날은 간다 (Bonus Track)</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>눈을 감으면 문득 그리운 날의 기억 \\n아직까지도 마음이 저려 오는 건 \\n\\n그건...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Going Home</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>집으로 돌아가는 길에\\n지는 햇살에 마음을 맡기고\\n나는 너의 일을 떠올리며\\n수많...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>야상곡 (夜想曲)</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>바람이 부는 것은 더운 내 맘 삭여주려 \\n계절이 다 가도록 나는 애만 태우네 \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>길</td>\n",
              "      <td>김윤아</td>\n",
              "      <td>아무도 가르쳐 주지 않아\\n이 길이 옳은지 다른 길로 가야 할지\\n난 저길 저 끝에...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             lyrics\n",
              "0           0  ...  너희는 하나님의 택하신\\n거룩하고 사랑스러운 자니 \\n긍율과 자비와 \\n겸손과 온유...\n",
              "1           1  ...  눈을 감으면 문득 그리운 날의 기억 \\n아직까지도 마음이 저려 오는 건 \\n\\n그건...\n",
              "2           2  ...  집으로 돌아가는 길에\\n지는 햇살에 마음을 맡기고\\n나는 너의 일을 떠올리며\\n수많...\n",
              "3           3  ...  바람이 부는 것은 더운 내 맘 삭여주려 \\n계절이 다 가도록 나는 애만 태우네 \\n...\n",
              "4           4  ...  아무도 가르쳐 주지 않아\\n이 길이 옳은지 다른 길로 가야 할지\\n난 저길 저 끝에...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHcfZpOKb8U"
      },
      "source": [
        "lyrics = list(df['lyrics'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAIMBppGYzpp"
      },
      "source": [
        "- Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5HTy3KyMhGR",
        "outputId": "0d1a551c-588e-46f7-ef6a-019abc819236"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lyrics)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print('단어 집합의 크기: %d' %vocab_size)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기: 21521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFb13pb9Y3MM"
      },
      "source": [
        "## 5. 훈련데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9JFYcJ-TQ8Y",
        "outputId": "3ce42a9f-2ccb-4770-e35e-81f654ea5753"
      },
      "source": [
        "%%time\n",
        "\n",
        "sequences = list()\n",
        "\n",
        "for lyric in lyrics:\n",
        "  for line in lyric.split('\\n'):\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)) :\n",
        "      sequence = encoded[:i+1]\n",
        "      sequences.append(sequence)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 538 ms, sys: 22.4 ms, total: 560 ms\n",
            "Wall time: 563 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv5oEFeLZOEY"
      },
      "source": [
        "- 학습데이터 확인 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDjYQyTnTWYQ",
        "outputId": "335c420c-5755-4635-d21e-3af3bea66385"
      },
      "source": [
        "print('학습에 사용할 샘플의 개수: %d' %len(sequences))\n",
        "print('샘플의 최대 길이: ' , max(len(l) for l in sequences))\n",
        "print('샘플의 평균 길이: ' , sum(map(len, sequences))/len(sequences))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습에 사용할 샘플의 개수: 112336\n",
            "샘플의 최대 길이:  215\n",
            "샘플의 평균 길이:  7.6879717988890475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Dm418DEkKqNn",
        "outputId": "438a6caa-8e28-476b-c581-1e7e34e442ea"
      },
      "source": [
        "plt.hist([len(f) for f in sequences] , bins = 100)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw64prwiZU3V"
      },
      "source": [
        "- 대체로 0 ~ 25사이에 집중되어 있으므로 패딩사이즈를 30으로 조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjQACcM4K7eO"
      },
      "source": [
        "MAX_LEN = 30"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt89MAd6TbhS",
        "outputId": "aa23c6be-2f44-421d-e1e0-528e276a9364"
      },
      "source": [
        "sequences = pad_sequences(sequences, maxlen = MAX_LEN, padding = 'pre')\n",
        "\n",
        "print(sequences)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...    0 4525 4526]\n",
            " [   0    0    0 ... 4525 4526 4527]\n",
            " [   0    0    0 ...    0 4528 1976]\n",
            " ...\n",
            " [ 279   29 3762 ... 1055 2344  149]\n",
            " [  29 3762 2419 ... 2344  149   96]\n",
            " [3762 2419   96 ...  149   96   10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2erXXMPTdGm",
        "outputId": "3563dde2-4548-4cb9-ee6a-5c15d105a17d"
      },
      "source": [
        "np.shape(sequences)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112336, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxYY_rDdTgnF"
      },
      "source": [
        "- 각 샘플의 마지막 단어를 레이블로 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PUixZR8Tej-"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y0S-0RTTgIP",
        "outputId": "476efab7-b5f1-460d-959e-405fb6bd36ad"
      },
      "source": [
        "np.shape(X) , np.shape(y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((112336, 29), (112336,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi2NtAdiTmBE"
      },
      "source": [
        "- 레이블에 대해 원-핫 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjZGbfuTlMB"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoOIQTDDTxLw"
      },
      "source": [
        "## 6. Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_tv2xhxTpZU"
      },
      "source": [
        "OUTPUT_DIM = 128\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size, output_dim = OUTPUT_DIM,\n",
        "                    input_length = MAX_LEN -1))\n",
        "\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCxNSl1QTzxd",
        "outputId": "6f422c61-9714-4780-dc53-34f5958be3ac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 29, 128)           2754688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 21521)             5530897   \n",
            "=================================================================\n",
            "Total params: 8,679,825\n",
            "Trainable params: 8,679,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqi7e5MwT0yP"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfyk_nF5aaDt"
      },
      "source": [
        "- Model Checkpoint, Early Stopping 옵션 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNAYL97eL6sZ"
      },
      "source": [
        "weights_folder = '../Param/'\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    os.path.join(weights_folder, \"2_LSTM_param.h5\"),\n",
        "    monitor = 'loss',\n",
        "    verbose = 0,\n",
        "    save_best_only = True,\n",
        "    mode = 'min'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor = 'loss',\n",
        "    restore_best_weights = True,\n",
        "    patience = 10\n",
        ")\n",
        "\n",
        "callbacks_list = [checkpoint,\n",
        "                 early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm_4NnxrbhQr"
      },
      "source": [
        "- 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHkG-XEua8Wl"
      },
      "source": [
        "model.load_weights(os.path.join(weights_folder, \"2_LSTM_param.h5\"))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmP0ROHDby0D"
      },
      "source": [
        "## 7. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTqm0eXgT2Fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f641337-229a-4991-a984-df6c5301130a"
      },
      "source": [
        "# 2시간 14분 소요\n",
        "%%time\n",
        "history = model.fit(X, y, \n",
        "                    epochs = 200,\n",
        "                    callbacks = callbacks_list,\n",
        "                    batch_size = 128,\n",
        "                    verbose = 1)\n",
        "\n",
        "model.save('../Param/2_LSTM_param.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "878/878 [==============================] - 59s 47ms/step - loss: 8.8702 - accuracy: 0.0117\n",
            "Epoch 2/200\n",
            "878/878 [==============================] - 43s 49ms/step - loss: 8.1357 - accuracy: 0.0201\n",
            "Epoch 3/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 7.4077 - accuracy: 0.0364\n",
            "Epoch 4/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 6.3758 - accuracy: 0.0865\n",
            "Epoch 5/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 5.3343 - accuracy: 0.1756\n",
            "Epoch 6/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 4.4557 - accuracy: 0.2787\n",
            "Epoch 7/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 3.7259 - accuracy: 0.3793\n",
            "Epoch 8/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 3.1427 - accuracy: 0.4670\n",
            "Epoch 9/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 2.6459 - accuracy: 0.5434\n",
            "Epoch 10/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 2.2806 - accuracy: 0.5944\n",
            "Epoch 11/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 1.9514 - accuracy: 0.6457\n",
            "Epoch 12/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 1.7357 - accuracy: 0.6764\n",
            "Epoch 13/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 1.5422 - accuracy: 0.7054\n",
            "Epoch 14/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 1.3755 - accuracy: 0.7287\n",
            "Epoch 15/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 1.2665 - accuracy: 0.7432\n",
            "Epoch 16/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 1.1666 - accuracy: 0.7553\n",
            "Epoch 17/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 1.0981 - accuracy: 0.7611\n",
            "Epoch 18/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 1.0288 - accuracy: 0.7707\n",
            "Epoch 19/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.9755 - accuracy: 0.7765\n",
            "Epoch 20/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.9403 - accuracy: 0.7799\n",
            "Epoch 21/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.9246 - accuracy: 0.7776\n",
            "Epoch 22/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.8936 - accuracy: 0.7839\n",
            "Epoch 23/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.8687 - accuracy: 0.7852\n",
            "Epoch 24/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.8624 - accuracy: 0.7845\n",
            "Epoch 25/200\n",
            "878/878 [==============================] - 42s 47ms/step - loss: 0.8453 - accuracy: 0.7858\n",
            "Epoch 26/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.8323 - accuracy: 0.7863\n",
            "Epoch 27/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.8202 - accuracy: 0.7873\n",
            "Epoch 28/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.8242 - accuracy: 0.7859\n",
            "Epoch 29/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.8065 - accuracy: 0.7877\n",
            "Epoch 30/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7983 - accuracy: 0.7876\n",
            "Epoch 31/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7969 - accuracy: 0.7866\n",
            "Epoch 32/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7981 - accuracy: 0.7864\n",
            "Epoch 33/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.8016 - accuracy: 0.7842\n",
            "Epoch 34/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7861 - accuracy: 0.7862\n",
            "Epoch 35/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7759 - accuracy: 0.7896\n",
            "Epoch 36/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7819 - accuracy: 0.7870\n",
            "Epoch 37/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7713 - accuracy: 0.7887\n",
            "Epoch 38/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7694 - accuracy: 0.7877\n",
            "Epoch 39/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7706 - accuracy: 0.7886\n",
            "Epoch 40/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7628 - accuracy: 0.7888\n",
            "Epoch 41/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7638 - accuracy: 0.7886\n",
            "Epoch 42/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7628 - accuracy: 0.7895\n",
            "Epoch 43/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7687 - accuracy: 0.7881\n",
            "Epoch 44/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7561 - accuracy: 0.7900\n",
            "Epoch 45/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7644 - accuracy: 0.7864\n",
            "Epoch 46/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.7580 - accuracy: 0.7889\n",
            "Epoch 47/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7499 - accuracy: 0.7919\n",
            "Epoch 48/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7450 - accuracy: 0.7902\n",
            "Epoch 49/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7539 - accuracy: 0.7887\n",
            "Epoch 50/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7450 - accuracy: 0.7899\n",
            "Epoch 51/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7448 - accuracy: 0.7900\n",
            "Epoch 52/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7521 - accuracy: 0.7879\n",
            "Epoch 53/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7457 - accuracy: 0.7889\n",
            "Epoch 54/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7430 - accuracy: 0.7902\n",
            "Epoch 55/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7489 - accuracy: 0.7887\n",
            "Epoch 56/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7463 - accuracy: 0.7870\n",
            "Epoch 57/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7397 - accuracy: 0.7896\n",
            "Epoch 58/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7466 - accuracy: 0.7892\n",
            "Epoch 59/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7410 - accuracy: 0.7914\n",
            "Epoch 60/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7339 - accuracy: 0.7913\n",
            "Epoch 61/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7401 - accuracy: 0.7887\n",
            "Epoch 62/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7314 - accuracy: 0.7920\n",
            "Epoch 63/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7447 - accuracy: 0.7883\n",
            "Epoch 64/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7412 - accuracy: 0.7891\n",
            "Epoch 65/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7339 - accuracy: 0.7901\n",
            "Epoch 66/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7416 - accuracy: 0.7880\n",
            "Epoch 67/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7447 - accuracy: 0.7876\n",
            "Epoch 68/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7349 - accuracy: 0.7912\n",
            "Epoch 69/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7319 - accuracy: 0.7889\n",
            "Epoch 70/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7404 - accuracy: 0.7875\n",
            "Epoch 71/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7287 - accuracy: 0.7913\n",
            "Epoch 72/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7324 - accuracy: 0.7904\n",
            "Epoch 73/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7304 - accuracy: 0.7907\n",
            "Epoch 74/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7293 - accuracy: 0.7913\n",
            "Epoch 75/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7311 - accuracy: 0.7889\n",
            "Epoch 76/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7265 - accuracy: 0.7921\n",
            "Epoch 77/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7335 - accuracy: 0.7893\n",
            "Epoch 78/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7299 - accuracy: 0.7915\n",
            "Epoch 79/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7286 - accuracy: 0.7892\n",
            "Epoch 80/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7279 - accuracy: 0.7898\n",
            "Epoch 81/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7221 - accuracy: 0.7930\n",
            "Epoch 82/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7336 - accuracy: 0.7893\n",
            "Epoch 83/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7248 - accuracy: 0.7902\n",
            "Epoch 84/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7299 - accuracy: 0.7910\n",
            "Epoch 85/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7291 - accuracy: 0.7903\n",
            "Epoch 86/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7219 - accuracy: 0.7894\n",
            "Epoch 87/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7205 - accuracy: 0.7908\n",
            "Epoch 88/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7274 - accuracy: 0.7913\n",
            "Epoch 89/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7227 - accuracy: 0.7914\n",
            "Epoch 90/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7204 - accuracy: 0.7909\n",
            "Epoch 91/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7287 - accuracy: 0.7905\n",
            "Epoch 92/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7241 - accuracy: 0.7916\n",
            "Epoch 93/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7283 - accuracy: 0.7898\n",
            "Epoch 94/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7223 - accuracy: 0.7927\n",
            "Epoch 95/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7269 - accuracy: 0.7899\n",
            "Epoch 96/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7253 - accuracy: 0.7914\n",
            "Epoch 97/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7138 - accuracy: 0.7935\n",
            "Epoch 98/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7148 - accuracy: 0.7933\n",
            "Epoch 99/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7115 - accuracy: 0.7930\n",
            "Epoch 100/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7183 - accuracy: 0.7916\n",
            "Epoch 101/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7180 - accuracy: 0.7928\n",
            "Epoch 102/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7317 - accuracy: 0.7891\n",
            "Epoch 103/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7254 - accuracy: 0.7897\n",
            "Epoch 104/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7173 - accuracy: 0.7924\n",
            "Epoch 105/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7175 - accuracy: 0.7900\n",
            "Epoch 106/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7215 - accuracy: 0.7897\n",
            "Epoch 107/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7159 - accuracy: 0.7917\n",
            "Epoch 108/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7195 - accuracy: 0.7910\n",
            "Epoch 109/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.7360 - accuracy: 0.7882\n",
            "Epoch 110/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7246 - accuracy: 0.7903\n",
            "Epoch 111/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7129 - accuracy: 0.7927\n",
            "Epoch 112/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7111 - accuracy: 0.7931\n",
            "Epoch 113/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7074 - accuracy: 0.7944\n",
            "Epoch 114/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7151 - accuracy: 0.7920\n",
            "Epoch 115/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7158 - accuracy: 0.7919\n",
            "Epoch 116/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7152 - accuracy: 0.7931\n",
            "Epoch 117/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7049 - accuracy: 0.7940\n",
            "Epoch 118/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7140 - accuracy: 0.7928\n",
            "Epoch 119/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7174 - accuracy: 0.7892\n",
            "Epoch 120/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7208 - accuracy: 0.7897\n",
            "Epoch 121/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7148 - accuracy: 0.7921\n",
            "Epoch 122/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7274 - accuracy: 0.7893\n",
            "Epoch 123/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7191 - accuracy: 0.7913\n",
            "Epoch 124/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7117 - accuracy: 0.7928\n",
            "Epoch 125/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7113 - accuracy: 0.7928\n",
            "Epoch 126/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7171 - accuracy: 0.7899\n",
            "Epoch 127/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7116 - accuracy: 0.7929\n",
            "Epoch 128/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7126 - accuracy: 0.7914\n",
            "Epoch 129/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7159 - accuracy: 0.7909\n",
            "Epoch 130/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7159 - accuracy: 0.7904\n",
            "Epoch 131/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7174 - accuracy: 0.7924\n",
            "Epoch 132/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7111 - accuracy: 0.7918\n",
            "Epoch 133/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7128 - accuracy: 0.7921\n",
            "Epoch 134/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7109 - accuracy: 0.7924\n",
            "Epoch 135/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7101 - accuracy: 0.7922\n",
            "Epoch 136/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7146 - accuracy: 0.7906\n",
            "Epoch 137/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7139 - accuracy: 0.7919\n",
            "Epoch 138/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7238 - accuracy: 0.7890\n",
            "Epoch 139/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7059 - accuracy: 0.7934\n",
            "Epoch 140/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7060 - accuracy: 0.7935\n",
            "Epoch 141/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7061 - accuracy: 0.7957\n",
            "Epoch 142/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7099 - accuracy: 0.7925\n",
            "Epoch 143/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7085 - accuracy: 0.7916\n",
            "Epoch 144/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7155 - accuracy: 0.7909\n",
            "Epoch 145/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7127 - accuracy: 0.7919\n",
            "Epoch 146/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7094 - accuracy: 0.7923\n",
            "Epoch 147/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7091 - accuracy: 0.7941\n",
            "Epoch 148/200\n",
            "878/878 [==============================] - 39s 45ms/step - loss: 0.7060 - accuracy: 0.7936\n",
            "Epoch 149/200\n",
            "878/878 [==============================] - 39s 44ms/step - loss: 0.7064 - accuracy: 0.7931\n",
            "Epoch 150/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7086 - accuracy: 0.7933\n",
            "Epoch 151/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7024 - accuracy: 0.7954\n",
            "Epoch 152/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7041 - accuracy: 0.7929\n",
            "Epoch 153/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7126 - accuracy: 0.7915\n",
            "Epoch 154/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7098 - accuracy: 0.7920\n",
            "Epoch 155/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7088 - accuracy: 0.7912\n",
            "Epoch 156/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7049 - accuracy: 0.7932\n",
            "Epoch 157/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7035 - accuracy: 0.7923\n",
            "Epoch 158/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7049 - accuracy: 0.7935\n",
            "Epoch 159/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7154 - accuracy: 0.7910\n",
            "Epoch 160/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7066 - accuracy: 0.7938\n",
            "Epoch 161/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7080 - accuracy: 0.7943\n",
            "Epoch 162/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7040 - accuracy: 0.7942\n",
            "Epoch 163/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7108 - accuracy: 0.7929\n",
            "Epoch 164/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7012 - accuracy: 0.7943\n",
            "Epoch 165/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7046 - accuracy: 0.7937\n",
            "Epoch 166/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7088 - accuracy: 0.7925\n",
            "Epoch 167/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7075 - accuracy: 0.7924\n",
            "Epoch 168/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7088 - accuracy: 0.7934\n",
            "Epoch 169/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7120 - accuracy: 0.7923\n",
            "Epoch 170/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7042 - accuracy: 0.7930\n",
            "Epoch 171/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7074 - accuracy: 0.7917\n",
            "Epoch 172/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7060 - accuracy: 0.7937\n",
            "Epoch 173/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7070 - accuracy: 0.7943\n",
            "Epoch 174/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7047 - accuracy: 0.7936\n",
            "Epoch 175/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7060 - accuracy: 0.7927\n",
            "Epoch 176/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7038 - accuracy: 0.7931\n",
            "Epoch 177/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.7045 - accuracy: 0.7917\n",
            "Epoch 178/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.7091 - accuracy: 0.7941\n",
            "Epoch 179/200\n",
            "878/878 [==============================] - 42s 47ms/step - loss: 0.7033 - accuracy: 0.7937\n",
            "Epoch 180/200\n",
            "878/878 [==============================] - 42s 47ms/step - loss: 0.7138 - accuracy: 0.7912\n",
            "Epoch 181/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.7035 - accuracy: 0.7934\n",
            "Epoch 182/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.7039 - accuracy: 0.7941\n",
            "Epoch 183/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.7115 - accuracy: 0.7925\n",
            "Epoch 184/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.7059 - accuracy: 0.7936\n",
            "Epoch 185/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.7084 - accuracy: 0.7940\n",
            "Epoch 186/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.7056 - accuracy: 0.7924\n",
            "Epoch 187/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.6996 - accuracy: 0.7960\n",
            "Epoch 188/200\n",
            "878/878 [==============================] - 43s 49ms/step - loss: 0.7063 - accuracy: 0.7920\n",
            "Epoch 189/200\n",
            "878/878 [==============================] - 43s 49ms/step - loss: 0.7015 - accuracy: 0.7940\n",
            "Epoch 190/200\n",
            "878/878 [==============================] - 44s 50ms/step - loss: 0.7021 - accuracy: 0.7936\n",
            "Epoch 191/200\n",
            "878/878 [==============================] - 44s 50ms/step - loss: 0.7050 - accuracy: 0.7921\n",
            "Epoch 192/200\n",
            "878/878 [==============================] - 43s 49ms/step - loss: 0.7166 - accuracy: 0.7900\n",
            "Epoch 193/200\n",
            "878/878 [==============================] - 42s 48ms/step - loss: 0.7055 - accuracy: 0.7937\n",
            "Epoch 194/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.7069 - accuracy: 0.7920\n",
            "Epoch 195/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.6956 - accuracy: 0.7953\n",
            "Epoch 196/200\n",
            "878/878 [==============================] - 41s 47ms/step - loss: 0.6958 - accuracy: 0.7943\n",
            "Epoch 197/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7041 - accuracy: 0.7933\n",
            "Epoch 198/200\n",
            "878/878 [==============================] - 41s 46ms/step - loss: 0.6958 - accuracy: 0.7958\n",
            "Epoch 199/200\n",
            "878/878 [==============================] - 40s 46ms/step - loss: 0.7072 - accuracy: 0.7915\n",
            "Epoch 200/200\n",
            "878/878 [==============================] - 40s 45ms/step - loss: 0.7056 - accuracy: 0.7923\n",
            "CPU times: user 2h 48min, sys: 10min 42s, total: 2h 58min 42s\n",
            "Wall time: 2h 14min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW1FCV2nUFuT"
      },
      "source": [
        "## 8. 결과 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZXmKDBWb_qA"
      },
      "source": [
        "### 1) 가사 생성함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHU4vUsoUIbz"
      },
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "  \n",
        "  init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기 위해 저장\n",
        "  sentence = ''\n",
        "\n",
        "\n",
        "  for _ in range(n):\n",
        "    # 현재 단어에 대한 정수 인코딩\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0] \n",
        "    # 데이터에 대한 패딩\n",
        "    encoded = pad_sequences([encoded], maxlen=MAX_LEN, padding='pre') \n",
        "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장\n",
        "    result = model.predict_classes(encoded, verbose=0)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items(): \n",
        "      if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "        break # 해당 단어가 예측 단어이므로 break\n",
        "    current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
        "  # for문이므로 이 행동을 다시 반복\n",
        "\n",
        "  sentence = init_word + sentence\n",
        "  \n",
        "  return sentence"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK3eXZ7KcPKm"
      },
      "source": [
        "### 2) 가사 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PavZm4THcWOB"
      },
      "source": [
        "- TF-IDF로 추출된 키워드로 가사 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snmsYfA7jFKG"
      },
      "source": [
        "keyword_list = ['아주',\n",
        "                '다시',\n",
        "                '사랑',\n",
        "                '눈물',\n",
        "                '순간',\n",
        "                '내겐',\n",
        "                '지금',\n",
        "                '모습',\n",
        "                '그대',\n",
        "                '마음']"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBrdGSzYjreX"
      },
      "source": [
        "gene_lyrics = []\n",
        "for keyword in keyword_list:\n",
        "  gene_lyrics.append(sentence_generation(model, tokenizer, keyword, 8))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrSAHLHCj4B9",
        "outputId": "cd0b7dd7-769a-4b47-a9e8-e178286ef199"
      },
      "source": [
        "gene_lyrics"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아주 오래된 기억 저편에 인사 너의 눈 지나 같은',\n",
              " '다시 못 올 지난날을 난 꾸밈없이 영원히 간직하리 함께',\n",
              " '사랑 하나로 그 모든 비난을 이길 순 없겠죠 안',\n",
              " '눈물 흘리고 난 또 그만큼 그대를 채워요 일 그댄',\n",
              " '순간 내가 미쳤었는지 헛된 살것같은데 술 없이는 못 지나고',\n",
              " '내겐 너무 쉬울 것만 같은데 날 찾을 수 있니',\n",
              " '지금 이 순간 간절히 내가 바라는 한 가지 마',\n",
              " '모습 사랑해 줄 수 없는 그 날을 증발시켜줘 다시',\n",
              " '그대 내 품에 안겨 눈을 감아요 꿈 숨이 꿈',\n",
              " '마음 가득 기댈 곳이 필요할 때 있는데 네게 잊은']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}